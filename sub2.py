# sub2.py  â€”â€” æœ€ç»ˆå®Œæ•´ä¿®å¤ç‰ˆï¼ˆä»…æ”¹å›¾æ ‡åˆ‡æ¢ï¼‰
from PyQt5.QtWidgets import QWidget, QPushButton
from ui.kimi import Ui_Form2
from PyQt5.QtCore import Qt, QObject, pyqtSignal, QThread, QTimer
from PyQt5 import QtGui
from PyQt5.QtCore import Qt, QRect
from PyQt5 import QtCore
import threading
import pyaudio
import wave
import os
import json
import time
import pygame  # ç”¨äºè¯­éŸ³æ§åˆ¶

# ---------------- å½•éŸ³è¯†åˆ«å¸¸é‡ ----------------
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
TEMP_WAV = "temp.wav"

# å…¨å±€å˜é‡ï¼Œå»¶è¿Ÿåˆå§‹åŒ–
pa = None
model = None

# ---------------- å¼‚æ­¥åˆå§‹åŒ–çº¿ç¨‹ ----------------
class InitializationThread(QThread):
    progress_update = pyqtSignal(str)  # è¿›åº¦ä¿¡å·
    init_finished = pyqtSignal(object, object)  # åˆå§‹åŒ–å®Œæˆä¿¡å· (pa, model)
    init_error = pyqtSignal(str)  # åˆå§‹åŒ–é”™è¯¯ä¿¡å·
    
    def run(self):
        try:
            global pa, model
            
            self.progress_update.emit("ğŸš€ è¯­éŸ³AIç³»ç»Ÿå¯åŠ¨ä¸­...")
            time.sleep(0.1)
            
            self.progress_update.emit("ğŸ“± æ­£åœ¨å¯¼å…¥ä¾èµ–åº“...")
            from use.web import KimiBot, speak
            
            self.progress_update.emit("ğŸ¤ æ­£åœ¨åˆå§‹åŒ–éŸ³é¢‘ç³»ç»Ÿ...")
            pa = pyaudio.PyAudio()
            
            self.progress_update.emit("ğŸ§  æ­£åœ¨åŠ è½½è¯­éŸ³è¯†åˆ«æ¨¡å‹...")
            self.progress_update.emit("ğŸ“‚ åŠ è½½ä¸­: vosk-model-small-cn-0.22")
            from vosk import Model, KaldiRecognizer
            model = Model("driver/vosk-model-small-cn-0.22")
            
            self.progress_update.emit("âœ… è¯­éŸ³è¯†åˆ«æ¨¡å‹åŠ è½½å®Œæˆ")
            self.progress_update.emit("ğŸŒ æ­£åœ¨åˆå§‹åŒ–Kimi AIæ¥å£...")
            
            # åˆ›å»ºKimiBotå®ä¾‹ï¼ˆä¸è®¾ç½®gui_callbackï¼Œåé¢åŠ¨æ€è®¾ç½®ï¼‰
            bot = KimiBot()
            self.progress_update.emit("âœ… Kimi AIæ¥å£åˆå§‹åŒ–å®Œæˆ")
            
            self.progress_update.emit("ğŸ‰ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!")
            self.progress_update.emit("ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨è¯­éŸ³äº¤äº’åŠŸèƒ½")
            
            # å‘é€åˆå§‹åŒ–å®Œæˆä¿¡å·
            self.init_finished.emit(bot, speak)
            
        except Exception as e:
            error_msg = f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}"
            self.progress_update.emit(f"âŒ {error_msg}")
            self.init_error.emit(error_msg)

# ---------------- ä¿¡å·æ¡¥ ----------------
class _SignalBridge(QObject):
    text_signal = pyqtSignal(str)
    answer_signal = pyqtSignal(str)

# ---------------- å½•éŸ³çº¿ç¨‹ ----------------
class RecordThread(QThread):
    def __init__(self, form_instance):
        super().__init__()
        self.form_instance = form_instance
        self.frames = []

    def run(self):
        global pa, model
        
        # æ£€æŸ¥æ˜¯å¦å·²åˆå§‹åŒ–
        if pa is None or model is None:
            self.form_instance.bridge.text_signal.emit("ç³»ç»Ÿå°šæœªåˆå§‹åŒ–å®Œæˆ")
            return
            
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        from vosk import KaldiRecognizer
        
        self.frames.clear()
        stream = pa.open(format=FORMAT,
                         channels=CHANNELS,
                         rate=RATE,
                         input=True,
                         frames_per_buffer=CHUNK)
        while getattr(self, "_running", False):
            self.frames.append(stream.read(CHUNK, exception_on_overflow=False))
        stream.stop_stream()
        stream.close()

        # ä¿å­˜ wav
        with wave.open(TEMP_WAV, 'wb') as wf:
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(pa.get_sample_size(FORMAT))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(self.frames))

        # è¯†åˆ«
        rec = KaldiRecognizer(model, RATE)
        with wave.open(TEMP_WAV, 'rb') as wf:
            while True:
                data = wf.readframes(4000)
                if not data:
                    break
                rec.AcceptWaveform(data)
            result = json.loads(rec.FinalResult())
        text = result.get("text", "").strip()

        # é€šè¿‡çˆ¶çª—å£çš„ä¿¡å·æ¡¥å›åˆ°ä¸»çº¿ç¨‹
        self.form_instance.bridge.text_signal.emit(text)
        if os.path.exists(TEMP_WAV):
            os.remove(TEMP_WAV)

# ---------------- ä¸»çª—å£ ----------------
class Form2(QWidget, Ui_Form2):
    def __init__(self, title="è¯­è¨€äººå·¥æ™ºèƒ½äº¤äº’å¹³å°"):
        super().__init__()
        self.setupUi(self)
        self.setWindowTitle(title)
        self.setWindowFlags(Qt.FramelessWindowHint)
        self.setAttribute(Qt.WA_TranslucentBackground)
        
        # ç«‹å³æ˜¾ç¤ºçª—å£
        self.show()
        
        # å¼ºåˆ¶å¤„ç†UIäº‹ä»¶ï¼Œç¡®ä¿ç•Œé¢ç«‹å³æ˜¾ç¤º
        from PyQt5.QtWidgets import QApplication
        QApplication.processEvents()

        # åˆå§‹åŒ–çŠ¶æ€
        self.bot = None
        self.speak_func = None
        self.system_ready = False
        self.is_speaking = False  # è¯­éŸ³è¾“å‡ºçŠ¶æ€
        self.current_ai_response = ""  # å½“å‰AIå›ç­”çš„å®Œæ•´å†…å®¹
        self.last_display_pos = 0  # ä¸Šæ¬¡æ˜¾ç¤ºä½ç½®
        self.last_speech_pos = 0  # ä¸Šæ¬¡è¯­éŸ³æ’­æŠ¥ä½ç½®
        self.is_processing = False  # æ˜¯å¦æ­£åœ¨å¤„ç†AIå›ç­”
        self.speech_queue = []  # è¯­éŸ³æ’­æŠ¥é˜Ÿåˆ—
        
        # æ˜¾ç¤ºåˆå§‹åŒ–ä¿¡æ¯
        self.answer.setPlainText("ğŸš€ è¯­éŸ³AIç³»ç»Ÿå¯åŠ¨ä¸­...\nğŸ’¡ é¡µé¢å·²å°±ç»ªï¼Œæ­£åœ¨åˆå§‹åŒ–...")
        self.question.setPlainText("ç³»ç»Ÿåˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨å€™...")

        # ä¿¡å·æ¡¥
        self.bridge = _SignalBridge()
        self.bridge.text_signal.connect(self.on_recognized)
        self.bridge.answer_signal.connect(self.on_streaming_answer)

        # å½•éŸ³æŒ‰é’®
        self.record_btn = self.findChild(QPushButton, "record")
        self.record_btn.setCheckable(True)
        self.record_btn.toggled.connect(self.toggle_record)
        
        # åˆå§‹ç¦ç”¨æŒ‰é’®
        self.record_btn.setEnabled(False)
        self.send.setEnabled(False)

        # å‘é€æŒ‰é’®
        self.send.clicked.connect(self.on_send)
        
        # å…³é—­æŒ‰é’®ï¼ˆpushButton_2 å³Ã—é”®ï¼‰
        self.pushButton_2.clicked.disconnect()  # æ–­å¼€åŸæœ‰çš„closeè¿æ¥
        self.pushButton_2.clicked.connect(self.close_with_speech_stop)
        
        # ä½¿ç”¨QTimerå»¶è¿Ÿå¯åŠ¨åˆå§‹åŒ–ï¼Œç¡®ä¿UIå…ˆæ˜¾ç¤º
        QTimer.singleShot(100, self.start_initialization)

        # çª—å£è¾¹ç¼˜æ‹–åŠ¨å‚æ•°
        self._resize_dir = None
        self._resize_flag = False
        self.EDGE_MARGIN = 8
        self.CURSOR_MAP = {
            'left':  Qt.SizeHorCursor,
            'right': Qt.SizeHorCursor,
            'top':   Qt.SizeVerCursor,
            'bottom':Qt.SizeVerCursor,
            'lt':    Qt.SizeFDiagCursor,
            'rt':    Qt.SizeBDiagCursor,
            'lb':    Qt.SizeBDiagCursor,
            'rb':    Qt.SizeFDiagCursor,
        }

    # ---------- å½•éŸ³æ§åˆ¶ ----------
    def toggle_record(self, checked):
        if not self.system_ready:
            self.update_initialization_progress("âš ï¸ ç³»ç»Ÿå°šæœªåˆå§‹åŒ–å®Œæˆï¼Œè¯·ç¨å€™...")
            self.record_btn.setChecked(False)
            return
            
        # å¦‚æœæ­£åœ¨å¤„ç†AIå›ç­”æˆ–è¯­éŸ³è¾“å‡ºï¼Œå…ˆä¸­æ–­æ‰€æœ‰è¿›ç¨‹
        if self.is_processing or self.is_speaking:
            self.interrupt_all_processes()
            
        if checked:          # å¼€å§‹å½•éŸ³
            self.answer.setPlainText("ğŸ¤ å½•éŸ³ä¸­...\nè¯·è¯´è¯ï¼Œå†æ¬¡ç‚¹å‡»ç»“æŸå½•éŸ³")
            self.record_btn.setIcon(QtGui.QIcon("images/å½•éŸ³æŒ‰é’®.png"))
            self.rec_thread = RecordThread(self)
            self.rec_thread._running = True
            self.rec_thread.start()
        else:                # ç»“æŸå½•éŸ³
            if hasattr(self, 'rec_thread'):
                self.rec_thread._running = False
                self.rec_thread.quit()
                self.rec_thread.wait()
            self.record_btn.setIcon(QtGui.QIcon("images/å½•éŸ³ç»“æŸ (1).png"))   # â† æ¢å¤é»˜è®¤å›¾æ ‡
            self.answer.setPlainText("ğŸ”„ æ­£åœ¨è¯†åˆ«è¯­éŸ³...\nè¯·ç¨å€™...")

    def on_recognized(self, text):
        if text and text != "ç³»ç»Ÿå°šæœªåˆå§‹åŒ–å®Œæˆ":
            self.question.setPlainText(text)
            self.answer.setPlainText(f"âœ… è¯†åˆ«ç»“æœ: {text}\nğŸ’¡ ç‚¹å‡»å‘é€æŒ‰é’®è·å–AIå›ç­”")
        elif text == "ç³»ç»Ÿå°šæœªåˆå§‹åŒ–å®Œæˆ":
            self.answer.setPlainText("âš ï¸ ç³»ç»Ÿå°šæœªåˆå§‹åŒ–å®Œæˆï¼Œè¯·ç¨å€™...")
        else:
            self.question.setPlainText("æœªæ£€æµ‹åˆ°è¯­éŸ³")
            self.answer.setPlainText("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³\nğŸ’¡ è¯·é‡æ–°å°è¯•å½•éŸ³")

    # ---------- å‘é€ ----------
    def on_send(self):
        q = self.question.toPlainText().strip()
        if not q or q in ["è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...", "ç³»ç»Ÿåˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨å€™...", "åˆå§‹åŒ–å¤±è´¥ï¼Œä»…æ”¯æŒæ–‡æœ¬è¾“å…¥"]:
            self.answer.setPlainText("âš ï¸ è¯·å…ˆè¾“å…¥æœ‰æ•ˆé—®é¢˜")
            return
            
        # å¦‚æœæ­£åœ¨å¤„ç†AIå›ç­”æˆ–è¯­éŸ³è¾“å‡ºï¼Œå…ˆä¸­æ–­æ‰€æœ‰è¿›ç¨‹
        if self.is_processing or self.is_speaking:
            self.interrupt_all_processes()
            
        if not self.system_ready:
            self.answer.setPlainText("âš ï¸ ç³»ç»Ÿå°šæœªå®Œå…¨åˆå§‹åŒ–ï¼Œæ­£åœ¨å°è¯•åŸºç¡€å›ç­”...")
            
        self.answer.setPlainText(f"ğŸ¤” æ­£åœ¨æ€è€ƒæ‚¨çš„é—®é¢˜...\né—®é¢˜: {q}\n")
        self.reset_states()  # é‡ç½®çŠ¶æ€
        threading.Thread(target=self._ask, args=(q,), daemon=True).start()

    def _ask(self, q):
        try:
            self.is_processing = True
            self.bridge.answer_signal.emit("ğŸ¤– AIæ­£åœ¨å›ç­”:\n\n")
            
            # å¤ç”¨ç°æœ‰çš„botå®ä¾‹ï¼Œä¸è¦é‡æ–°åˆ›å»º
            if self.bot is None:
                from use.web import KimiBot
                self.bot = KimiBot(gui_callback=self._on_streaming_content)
            else:
                # æ›´æ–°ç°æœ‰botçš„å›è°ƒå‡½æ•°
                self.bot.gui_callback = self._on_streaming_content
                
            answer = self.bot.send_message(q)
            
            # å¤„ç†å®Œæˆåçš„æ¸…ç†
            self.is_processing = False
                
        except Exception as e:
            error_msg = f"âŒ è·å–å›ç­”æ—¶å‡ºé”™: {str(e)}"
            self.bridge.answer_signal.emit(error_msg)
            self.is_processing = False

    def _on_streaming_content(self, content):
        """å¤„ç†æµå¼è¾“å‡ºå†…å®¹"""
        if not self.is_processing:  # å¦‚æœå·²è¢«ä¸­æ–­ï¼Œç›´æ¥è¿”å›
            return
            
        if content.strip():
            # ç´¯ç§¯å®Œæ•´å†…å®¹
            self.current_ai_response = content
            # æ›´æ–°æ˜¾ç¤º
            self.bridge.answer_signal.emit(f"ğŸ¤– AIå›ç­”:\n\n{content}")
            
            # å®ç°åŒæ­¥çš„è¯­éŸ³æ’­æŠ¥
            if self.speak_func is not None:
                self._process_speech_sync(content)

    def _process_speech_sync(self, content):
        """åŒæ­¥å¤„ç†è¯­éŸ³æ’­æŠ¥"""
        # è·å–æ–°å¢å†…å®¹
        new_content = content[self.last_speech_pos:]
        
        if len(new_content) > 10:  # ç§¯ç´¯ä¸€å®šå­—ç¬¦åå¼€å§‹å¤„ç†
            # å¯»æ‰¾å¥å­è¾¹ç•Œ
            sentence_markers = ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?', 'ï¼Œ', ',', 'ï¼›', ';']
            best_end = -1
            
            # ä»åå¾€å‰å¯»æ‰¾æœ€ä½³æ–­å¥ç‚¹
            for i in range(len(new_content) - 1, max(0, len(new_content) - 50), -1):
                if new_content[i] in sentence_markers:
                    best_end = i
                    break
            
            if best_end > 5:  # æ‰¾åˆ°åˆé€‚çš„æ–­å¥ç‚¹
                speech_text = new_content[:best_end + 1].strip()
                if speech_text and not self.is_speaking:
                    self.last_speech_pos += best_end + 1
                    # ç«‹å³å¼€å§‹è¯­éŸ³æ’­æŠ¥ï¼Œå®ç°åŒæ­¥
                    threading.Thread(target=self._speak_immediately, args=(speech_text,), daemon=True).start()

    def _speak_immediately(self, text):
        """ç«‹å³è¯­éŸ³æ’­æŠ¥"""
        if not self.is_processing:  # æ£€æŸ¥æ˜¯å¦å·²è¢«ä¸­æ–­
            return
            
        try:
            self.is_speaking = True
            self.speak_func(text)
        except Exception as e:
            print(f"è¯­éŸ³æ’­æŠ¥é”™è¯¯: {e}")
        finally:
            self.is_speaking = False

    def on_streaming_answer(self, text):
        """å¤„ç†æµå¼è¾“å‡ºçš„å›ç­”"""
        self.answer.setPlainText(text)
        
        # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        cursor = self.answer.textCursor()
        cursor.movePosition(cursor.End)
        self.answer.setTextCursor(cursor)

    def stop_speech(self):
        """åœæ­¢å½“å‰è¯­éŸ³è¾“å‡º"""
        try:
            if pygame.mixer.get_init():
                pygame.mixer.music.stop()
            self.is_speaking = False
        except Exception as e:
            print(f"åœæ­¢è¯­éŸ³å‡ºé”™: {e}")

    def stop_speech_and_reset(self):
        """åœæ­¢è¯­éŸ³å¹¶é‡ç½®çŠ¶æ€"""
        self.interrupt_all_processes()
        self.reset_states()
        print("è¯­éŸ³è¾“å‡ºå·²ä¸­æ–­å¹¶é‡ç½®çŠ¶æ€")

    def close_with_speech_stop(self):
        """å…³é—­çª—å£å‰å…ˆåœæ­¢æ‰€æœ‰è¿›ç¨‹"""
        self.interrupt_all_processes()
        self.close()

    # ---------- è¾¹ç¼˜æ‹–åŠ¨ ----------
    def mousePressEvent(self, event):
        if event.button() == QtCore.Qt.LeftButton and not self.isMaximized():
            self.m_flag = True
            self.m_Position = event.globalPos() - self.pos()
            event.accept()
            self.setCursor(QtGui.QCursor(QtCore.Qt.OpenHandCursor))
        if event.button() == QtCore.Qt.LeftButton and self._resize_dir:
            self._resize_flag = True
            self._resize_start = event.globalPos()
            self._start_geo = self.geometry()
            event.accept()

    def mouseMoveEvent(self, event):
        if QtCore.Qt.LeftButton and getattr(self, 'm_flag', False):
            self.move(event.globalPos() - self.m_Position)
            event.accept()
            return
        if getattr(self, '_resize_flag', False) and self._resize_dir:
            delta = event.globalPos() - self._resize_start
            g = self._start_geo
            new_geo = QRect(g)
            if 'left'  in self._resize_dir: new_geo.setLeft  (g.left()   + delta.x())
            if 'right' in self._resize_dir: new_geo.setRight (g.right()  + delta.x())
            if 'top'   in self._resize_dir: new_geo.setTop   (g.top()    + delta.y())
            if 'bottom'in self._resize_dir: new_geo.setBottom(g.bottom() + delta.y())
            self.setGeometry(new_geo)
            event.accept()
        else:
            self._update_cursor_shape(event.pos())

    def mouseReleaseEvent(self, event):
        if getattr(self, 'm_flag', False):
            self.m_flag = False
            self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))
        if getattr(self, '_resize_flag', False):
            self._resize_flag = False
            self.setCursor(QtGui.QCursor(QtCore.Qt.ArrowCursor))

    def _update_cursor_shape(self, pos):
        w, h = self.width(), self.height()
        x, y = pos.x(), pos.y()
        margin = self.EDGE_MARGIN
        left, right = x < margin, x > w - margin
        top, bottom = y < margin, y > h - margin
        if top and left:      self._resize_dir = 'lt'
        elif top and right:   self._resize_dir = 'rt'
        elif bottom and left: self._resize_dir = 'lb'
        elif bottom and right:self._resize_dir = 'rb'
        elif left:            self._resize_dir = 'left'
        elif right:           self._resize_dir = 'right'
        elif top:             self._resize_dir = 'top'
        elif bottom:          self._resize_dir = 'bottom'
        else:
            self._resize_dir = None
            self.setCursor(Qt.ArrowCursor)
            return
        self.setCursor(QtGui.QCursor(self.CURSOR_MAP[self._resize_dir]))

    # ---------- å¼‚æ­¥åˆå§‹åŒ– ----------
    def start_initialization(self):
        """å¯åŠ¨å¼‚æ­¥åˆå§‹åŒ–"""
        self.init_thread = InitializationThread()
        self.init_thread.progress_update.connect(self.update_initialization_progress)
        self.init_thread.init_finished.connect(self.on_initialization_finished)
        self.init_thread.init_error.connect(self.on_initialization_error)
        self.init_thread.start()
        
    def update_initialization_progress(self, message):
        """æ›´æ–°åˆå§‹åŒ–è¿›åº¦"""
        current_text = self.answer.toPlainText()
        # ä¿æŒæœ€è¿‘8è¡Œä¿¡æ¯
        lines = current_text.split('\n')
        if len(lines) > 8:
            lines = lines[-7:]  # ä¿ç•™æœ€è¿‘7è¡Œï¼ŒåŠ ä¸Šæ–°çš„ä¸€è¡Œ
        
        lines.append(message)
        self.answer.setPlainText('\n'.join(lines))
        
        # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        cursor = self.answer.textCursor()
        cursor.movePosition(cursor.End)
        self.answer.setTextCursor(cursor)
        
    def on_initialization_finished(self, bot, speak_func):
        """åˆå§‹åŒ–å®Œæˆ"""
        self.bot = bot
        self.speak_func = speak_func
        self.system_ready = True
        
        # åˆå§‹åŒ–pygame mixerç”¨äºè¯­éŸ³æ§åˆ¶
        try:
            if not pygame.mixer.get_init():
                pygame.mixer.init()
        except Exception as e:
            print(f"pygameåˆå§‹åŒ–å¤±è´¥: {e}")
        
        # å¯ç”¨æŒ‰é’®
        self.record_btn.setEnabled(True)
        self.send.setEnabled(True)
        
        # æ›´æ–°UIæç¤º
        self.update_initialization_progress("=" * 40)
        self.update_initialization_progress("ğŸ‰ ç³»ç»Ÿå°±ç»ªï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨!")
        self.update_initialization_progress("ğŸ’¬ æ‚¨å¯ä»¥:")
        self.update_initialization_progress("  â€¢ åœ¨æ–‡æœ¬æ¡†è¾“å…¥é—®é¢˜")
        self.update_initialization_progress("  â€¢ ç‚¹å‡»å½•éŸ³æŒ‰é’®è¿›è¡Œè¯­éŸ³è¾“å…¥")
        
        # é‡ç½®é—®é¢˜æ¡†
        self.question.setPlainText("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...")
        
    def on_initialization_error(self, error_message):
        """åˆå§‹åŒ–é”™è¯¯"""
        self.update_initialization_progress("=" * 40)
        self.update_initialization_progress("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥!")
        self.update_initialization_progress(f"é”™è¯¯ä¿¡æ¯: {error_message}")
        self.update_initialization_progress("è¯·æ£€æŸ¥ä¾èµ–ç¯å¢ƒå’Œæ¨¡å‹æ–‡ä»¶")
        
        # åªå¯ç”¨æ–‡æœ¬è¾“å…¥ï¼ˆå‡è®¾KimiBotå¯èƒ½è¿˜èƒ½å·¥ä½œï¼‰
        self.send.setEnabled(True)
        self.question.setPlainText("åˆå§‹åŒ–å¤±è´¥ï¼Œä»…æ”¯æŒæ–‡æœ¬è¾“å…¥")

    # ---------- èµ„æºæ¸…ç† ----------
    def closeEvent(self, event):
        """å…³é—­çª—å£æ—¶æ¸…ç†èµ„æº"""
        # ä¸­æ–­æ‰€æœ‰è¿›ç¨‹
        self.interrupt_all_processes()
        
        # å…³é—­æµè§ˆå™¨å®ä¾‹
        if self.bot is not None:
            try:
                self.bot.quit_browser()
            except Exception as e:
                print(f"å…³é—­æµè§ˆå™¨å‡ºé”™: {e}")
        
        # åœæ­¢åˆå§‹åŒ–çº¿ç¨‹
        if hasattr(self, 'init_thread') and self.init_thread.isRunning():
            self.init_thread.quit()
            self.init_thread.wait()
            
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(TEMP_WAV):
            try:
                os.remove(TEMP_WAV)
            except:
                pass
                
        super().closeEvent(event)

    def reset_states(self):
        """é‡ç½®æ‰€æœ‰ç›¸å…³çŠ¶æ€"""
        self.current_ai_response = ""
        self.last_display_pos = 0
        self.last_speech_pos = 0
        self.is_processing = False
        self.speech_queue.clear()

    def interrupt_all_processes(self):
        """ä¸­æ–­æ‰€æœ‰æ­£åœ¨è¿›è¡Œçš„è¿›ç¨‹"""
        # åœæ­¢å¤„ç†æ ‡å¿—
        self.is_processing = False
        
        # åœæ­¢è¯­éŸ³è¾“å‡º
        self.stop_speech()
        
        # å¦‚æœæœ‰å½•éŸ³çº¿ç¨‹åœ¨è¿è¡Œï¼Œåœæ­¢å®ƒ
        if hasattr(self, 'rec_thread') and self.rec_thread.isRunning():
            self.rec_thread._running = False
            self.rec_thread.quit()
            self.rec_thread.wait()
        
        # é‡ç½®å½•éŸ³æŒ‰é’®çŠ¶æ€
        self.record_btn.setChecked(False)
        self.record_btn.setIcon(QtGui.QIcon("images/å½•éŸ³ç»“æŸ (1).png"))
        
        print("æ‰€æœ‰è¿›ç¨‹å·²ä¸­æ–­")